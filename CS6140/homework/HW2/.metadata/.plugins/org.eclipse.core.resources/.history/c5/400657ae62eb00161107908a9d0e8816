# TODO: Add comment
# 
# Author: lenovo
###############################################################################
library(pastecs)
library(leaps)
options(scipen=100)
options(digits=2)

mydata <- read.table("prostate.txt")
as.data.frame(mydata)
trainSet <- mydata[mydata$train == "TRUE", -c(10)]
testSet <- mydata[mydata$train == "FALSE", -c(10)]
y.test <- testSet$lpsa

# identify outliers
m.dist.order <- order(mahalanobis(trainSet, colMeans(trainSet), cov(trainSet)), decreasing=TRUE)
is.outlier   <- rep(FALSE, nrow(trainSet))
is.outlier[m.dist.order[1:8]] <- TRUE

trainSet_Outlier <- cbind(trainSet, is.outlier)
trainSet <- trainSet_Outlier[trainSet_Outlier$is.outlier == FALSE, -c(10)]

# one variable summary
summary(trainSet)
stat.desc(trainSet, basic=F)
stat.desc(trainSet, desc=F)

# two variable summary
round(cor(trainSet), digits=2)
pairs(trainSet)

# Assumption of Normality
fit <- lm(lpsa ~ ., data=trainSet)
y <- fit$residuals
fit.summary <- summary(fit)
qqnorm(y, ylim=c(-2.5,2.5))
abline(a=0,b=1,col="red")

# variable selection 
# all subset
regfit.full <- regsubsets(lpsa ~ ., data=trainSet)
reg.summary <- summary(regfit.full)
reg.summary

par(mfrow=c(2,2))
plot(reg.summary$rss, xlab="Number of variables", ylab="RSS", type='l')
plot(reg.summary$adjr2, xlab="Number of variables", ylab="adjR2", type='l')
plot(reg.summary$cp, xlab="Number of variables", ylab="Cp", type='l')
plot(reg.summary$bic, xlab="Number of variables", ylab="BIC", type='l')

coef(regfit.full, which.min(reg.summary$bic))

#require(RCurl)
#ch09ta01.file <- getURL("https://netfiles.umn.edu/users/nacht001/www/nachtsheim/5th/KutnerData/Chapter%20%209%20Data%20Sets/CH09TA01.txt",
#		ssl.verifypeer=FALSE)

#X <- read.table(textConnection(ch09ta01.file), sep='')
#dimnames(X)[[2]] <- c('blood', 'prog', 'enz', 'liver', 'age', 'female', 'modAlc', 'heavyAlc', 'surv', 'lsurv')

# lasso
library(glmnet)
grid=10^seq(10, -2, length=100)
lasso.mod <- glmnet(x=as.matrix(trainSet[,-c(9)]), y=trainSet[,9], alpha=1, lambda=grid)
windows()
plot(lasso.mod)

cv.out <- cv.glmnet(x=as.matrix(trainSet[,-c(9)]), y=trainSet[,9], alpha=1)
plot(cv.out)

coef(cv.out, s="lambda.min")
y.pred.lasso <- predict(cv.out, newx=as.matrix(testSet[,-c(9)]), s="lambda.min")
sum((y.pred.lasso - y.test)^2)