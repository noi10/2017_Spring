crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 3 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
summary(glmulti.logistic.out)
#glmulti.logistic.out@formulas
#summary(glmulti.logistic.out@objects[[1]])
library(glmulti)
library(glmpath)
library(pastecs)
library(knitr)
Mydata <- read.table("SouthAfricanHeartDisease.txt", sep=",", stringsAsFactors = FALSE, header = TRUE)
Mydata <- Mydata[,-1]
Mydata[,5][Mydata[,5]=="Present"] <- 1
Mydata[,5][Mydata[,5]=="Absent"] <- 0
Mydata[,5] <- as.integer(Mydata[,5])
predictors <- Mydata[,1:9]
response <- Mydata[,10]
sum(is.na(Mydata))
train <- sample(x=1:nrow(Mydata), size=nrow(Mydata)/2)
trainSet <- Mydata[train,]
one.variable.summary <- summary(trainSet, digits=2)
one.variable.summary
format(round(stat.desc(trainSet, basic=F), 2), nsmall = 2)
format(round(stat.desc(trainSet, desc=F), 2), nsmall=2)
round(cor(trainSet), digits=2)
pairs(trainSet)
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 3 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
glmulti.summary <- summary(glmulti.logistic.out)
plot(glmulti.summary$aic)
library(pastecs)
library(leaps)
library(glmnet)
library(knitr)
#options(digits=4)
mydata <- as.data.frame(read.table("prostate.txt"))
trainSet <- mydata[mydata$train == "TRUE", -c(10)]
testSet <- mydata[mydata$train == "FALSE", -c(10)]
x.test <- model.matrix(lpsa ~ ., data = testSet)
y.test <- testSet$lpsa
sum(is.na.data.frame(mydata))
# identify outliers
m.dist <- sort(mahalanobis(trainSet, colMeans(trainSet), cov(trainSet)), decreasing=TRUE)
plot(m.dist, ylab="manalanobis distance", xlab="index of m.dist",
main = "Outliers Identification")
# one variable summary
one.variable.summary <- summary(trainSet, digits=2)
one.variable.summary
format(round(stat.desc(trainSet, basic=F), 2), nsmall = 2)
format(round(stat.desc(trainSet, desc=F), 2), nsmall=2)
# two variable summary
round(cor(trainSet), digits=2)
pairs(trainSet)
# Assumption of Normality
fit <- lm(lpsa ~ ., data=trainSet)
y <- fit$residuals
fit.summary <- summary(fit)
qqnorm(y, ylim=c(-2.5,2.5))
abline(a=0,b=1,col="red")
# variable selection
# all subset
regfit.full <- regsubsets(lpsa ~ ., data=trainSet)
reg.summary <- summary(regfit.full)
reg.summary
par(mfrow=c(2,2))
plot(reg.summary$rss, xlab="Number of variables", ylab="RSS", type='l')
plot(reg.summary$adjr2, xlab="Number of variables", ylab="adjR2", type='l')
plot(reg.summary$cp, xlab="Number of variables", ylab="Cp", type='l')
abline(a=0, b=1, lty=3, lwd=2)
plot(reg.summary$bic, xlab="Number of variables", ylab="BIC", type='l')
coefi <- coef(regfit.full, which.min(reg.summary$bic))
y.pred.full2 <- x.test[, names(coefi)] %*% coefi
predict.full2 <- mean((y.pred.full2 - y.test)^2)
coefi
coefi <- coef(regfit.full, 3)
y.pred.full3 <- x.test[, names(coefi)] %*% coefi
predict.full3 <- mean((y.pred.full3 - y.test)^2)
coefi
reg.summary
reg.summary$bic
glmulti.summary$aic
glmulti.summary$bic
gomulti.summary
glmulti.summary
knitr::opts_chunk$set(echo = TRUE)
library(glmulti)
library(glmpath)
library(pastecs)
library(knitr)
Mydata <- read.table("SouthAfricanHeartDisease.txt", sep=",", stringsAsFactors = FALSE, header = TRUE)
Mydata[,6][Mydata[,6]=="Present"] <- 1
Mydata[,6][Mydata[,6]=="Absent"] <- 0
Mydata <- Mydata[,-1]
Mydata[,6] <- as.integer(Mydata[,6])
predictors <- Mydata[,1:9]
response <- Mydata[,10]
train <- sample(x=1:nrow(Mydata), size=nrow(Mydata)/2)
trainSet <- Mydata[train,]
sum(is.na(Mydata))
one.variable.summary <- summary(trainSet, digits=2)
one.variable.summary
format(round(stat.desc(trainSet, basic=F), 2), nsmall = 2)
knitr::opts_chunk$set(echo = TRUE)
library(glmulti)
library(glmpath)
library(pastecs)
library(knitr)
Mydata <- read.table("SouthAfricanHeartDisease.txt", sep=",", stringsAsFactors = FALSE, header = TRUE)
Mydata <- Mydata[,-1]
Mydata[,5][Mydata[,5]=="Present"] <- 1
Mydata[,5][Mydata[,5]=="Absent"] <- 0
Mydata[,5] <- as.integer(Mydata[,5])
predictors <- Mydata[,1:9]
response <- Mydata[,10]
train <- sample(x=1:nrow(Mydata), size=nrow(Mydata)/2)
trainSet <- Mydata[train,]
sum(is.na(Mydata))
one.variable.summary <- summary(trainSet, digits=2)
one.variable.summary
format(round(stat.desc(trainSet, basic=F), 2), nsmall = 2)
format(round(stat.desc(trainSet, desc=F), 2), nsmall=2)
round(cor(trainSet), digits=2)
pairs(trainSet)
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 3 best models
plotty = T, report = T,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
#glmulti.logistic.out@formulas
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 10,         # Keep 10 best models
plotty = T, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
sum(is.na(Mydata))
one.variable.summary <- summary(trainSet, digits=2)
one.variable.summary
format(round(stat.desc(trainSet, basic=F), 2), nsmall = 2)
format(round(stat.desc(trainSet, desc=F), 2), nsmall=2)
round(cor(trainSet), digits=2)
pairs(trainSet)
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 10,         # Keep 10 best models
plotty = T, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 5,         # Keep 10 best models
plotty = T, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 10 best models
plotty = T, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 10 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
#glmulti.logistic.out@formulas
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 10 best models
plotty = F, report = F,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
#glmulti.logistic.out@formulas
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 3,         # Keep 3 best models
plotty = T, report = T,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
glmulti.logistic.out <-
glmulti(chd ~ ., data = trainSet,
level = 1,               # Interaction considered
method = "h",            # Exhaustive approach
crit = "aic",            # AIC as criteria
confsetsize = 10,         # Keep 3 best models
plotty = T, report = T,  # No plot or interim reports
fitfunction = "glm",     # glm function
family = binomial)       # binomial family for logistic regression
library(glmulti)
library(glmpath)
library(pastecs)
library(knitr)
Mydata <- read.table("SouthAfricanHeartDisease.txt", sep=",", stringsAsFactors = FALSE, header = TRUE)
Mydata <- Mydata[,-1]
Mydata[,5][Mydata[,5]=="Present"] <- 1
Mydata[,5][Mydata[,5]=="Absent"] <- 0
Mydata[,5] <- as.integer(Mydata[,5])
predictors <- Mydata[,1:9]
response <- Mydata[,10]
sum(is.na(Mydata))
train <- sample(x=1:nrow(Mydata), size=nrow(Mydata)/2)
trainSet <- Mydata[train,]
one.variable.summary <- summary(trainSet, digits=2)
one.variable.summary
format(round(stat.desc(trainSet, basic=F), 2), nsmall = 2)
format(round(stat.desc(trainSet, desc=F), 2), nsmall=2)
round(cor(trainSet), digits=2)
pairs(trainSet)
#glmulti.logistic.out <-
#  glmulti(chd ~ ., data = trainSet,
#          level = 1,               # Interaction considered
#          method = "h",            # Exhaustive approach
#          crit = "aic",            # AIC as criteria
#          confsetsize = 10,         # Keep 3 best models
#          plotty = T, report = T,  # No plot or interim reports
#          fitfunction = "glm",     # glm function
#          family = binomial)       # binomial family for logistic regression
glmulti.logistic.out <- glmulti(chd~. , data=trainSet, level=1, fitfunction="glm", crit = "aic", confsetsize=512)
plot(glmulti.logistic.out)
#glmulti.summary <- summary(glmulti.logistic.out)
#glmulti.logistic.out@formulas
#summary(glmulti.logistic.out@objects[[1]])
fit.cv.glmpath <- cv.glmpath(x=as.matrix(predictors[train,]),
y=response[train],
family=binomial, nfold=10, plot.it=T)
fit.glmpath <- glmpath(x=as.matrix(predictors[train,]),
y=response[train], family=binomial)
glmulti.logistic.out <- glmulti(chd~. , data=trainSet, level=1, fitfunction="glm", crit = "aic", confsetsize=512)
plot(glmulti.logistic.out)
glmulti.logistic.out <- glmulti(chd~. , data=trainSet, level=1, fitfunction="glm", crit = "aic", confsetsize=512)
glmulti.logistic.out <- glmulti(chd~. , data=trainSet, level=1, fitfunction="glm", crit = "aic", confsetsize=512)
plot(glmulti.logistic.out)
glmulti.logistic.out <-
glmulti(chd~. , data=trainSet, level=1, fitfunction="glm", crit = "aic",
confsetsize=512, plotty = F, report = F)
plot(glmulti.logistic.out)
setwd("C:/Users/Bobo/Desktop/2017_Spring/CS6140/scripts")
X <- read.table("smokingAndObesity.txt", sep=" ", as.is=TRUE, header=TRUE)
X <- X[order(X$age),]
# factor for 'smoking status'
X$smokeF <- factor(X$smoke)
head(X)
table(X$over_wt)
X$over_wtF <- factor(abs(X$over_wt - 2), levels=c(0,1))
table(X$over_wtF)
head(X)
View(X)
fit<- glm(over_wtF ~ smokeF, family=binomial, data=X)
summary(fit)
fit<- glm(over_wtF ~ age + smokeF + age*smokeF, family=binomial, data=X)
summary(fit)
library(faraway)
data(orings)
?orings
orings
library(knitr)
library(multtest)
t.test(golub[2972, gol.fac=="ALL"]-golub[2989, gol.fac=="ALL"], alternative = "less")
library(knitr)
library(multtest)
data(golub)
gol.fac <- factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
t.test(golub[2972, gol.fac=="ALL"], mu=-0.9, alternative = "greater")
t.test(golub[2972, gol.fac=="ALL"],golub[2972, gol.fac=="AML"])
t.test(golub[2972, gol.fac=="ALL"]-golub[2989, gol.fac=="ALL"], alternative = "less")
t.test(golub[2972, gol.fac=="ALL"], golub[2989, gol.fac=="ALL"]，alternative = "less" )
t.test(golub[2972, gol.fac=="ALL"]-golub[2989, gol.fac=="ALL"], alternative = "less")
t.test(golub[2972, gol.fac=="ALL"], golub[2989, gol.fac=="ALL"]，alternative = "less"， paired=T )
res <- golub[2972,] > -0.6
binom.test(sum(res), length(res), p=0.5, alternative = "less")
res <- golub[2972,gol.fac=="ALL"] > -0.6
binom.test(sum(res), length(res), p=0.5, alternative = "less")
# problem 1
library(multtest)
data(golub)
gol.fac <- factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
# (a)
t.test(golub[2972, gol.fac=="ALL"], mu=-0.9, alternative = "greater")
# (b)
t.test(golub[2972, gol.fac=="ALL"],golub[2972, gol.fac=="AML"])
# (c)
t.test(golub[2972, gol.fac=="ALL"]-golub[2989, gol.fac=="ALL"], alternative = "less")
t.test(golub[2972, gol.fac=="ALL"], golub[2989, gol.fac=="ALL"], alternative = "less", paired=T )
# (d)
res <- golub[2972, gol.fac=="ALL"] < golub[2989, gol.fac=="ALL"]
binom.test(sum(res), length(res), p=1/2, alternative = "greater")
# (e)
res <- golub[2972,gol.fac=="ALL"] > -0.6
binom.test(sum(res), length(res), p=0.5, alternative = "less")
# (f)
resALL <- golub[2972, gol.fac=="ALL"] < -0.6
obsALL <- sum(resALL); nALL <- length(resALL)
resAML <- golub[2972, gol.fac=="AML"] < -0.6
obsAML <- sum(resAML); nAML <- length(resAML)
prop.test( x=c(obsALL, obsAML), n=c( nALL, nAML ), alternative="two.sided")
# problem 2
rm(list=ls())
# (a)
2000*0.05
# (b)
pbinom(89, size=2000, prob=0.05)
# problem 3
rm(list=ls())
#(a)
x.sim <- matrix(rnorm(10000*20, mean=3, sd=4), ncol=20)
tstat <- function(x) (mean(x)-3)/sd(x)*sqrt(length(x))
tstat.sim <- apply(x.sim, 1, tstat)
power.sim <- mean(tstat.sim > qt(0.3, df=19) & tstat.sim < qt(0.4, df=19))
power.sim+c(-1,0,1)*qnorm(0.975)*sqrt(power.sim*(1-power.sim)/10000)
x.sim <- matrix(rnorm(10000*20, mean=3, sd=4), ncol=20)
tstat <- function(x) (mean(x)-3)/sd(x)*sqrt(length(x))
tstat.sim <- apply(x.sim, 1, tstat)
power.sim <- mean(tstat.sim > qt(0.9, df=19) )
power.sim+c(-1,0,1)*qnorm(0.975)*sqrt(power.sim*(1-power.sim)/10000)
# problem 4
rm(list=ls())
# (a)
data(golub, package = "multtest")
gol.fac <- factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
p.values <- apply(golub, 1, function(x)
{
xALL = t(as.matrix(x))[,gol.fac=="ALL"]
xAML = t(as.matrix(x))[,gol.fac=="AML"]
t.test(xALL, xAML)$p.value
}
)
p.bon <-p.adjust(p=p.values, method="bonferroni")
p.fdr <-p.adjust(p=p.values, method="fdr")
sum(p.values<0.05)
sum(p.bon<0.05)
sum(p.fdr<0.05)
# (b)
golub.gnames[,2][order(p.values)][1:3]
golub.gnames[,2][order(p.bon)][1:3]
golub.gnames[,2][order(p.fdr)][1:3]
# problem 5
rm(list=ls())
# (a)
# Wald.CI
Wald.CI <- function(x, n, conf.level) {
p <- x/n
z <- qnorm(1-(1-conf.level)/2)
p + c(-1,1)*z*sqrt(p*(1-p)/n)
}
# Wilson.CI
Wilson.CI <- function(x, n, conf.level) {
p <- x/n
z <- qnorm(1-(1-conf.level)/2)
(x+z^2/2)/(n+z^2) + c(-1, 1)*(z*sqrt(n)/(n+z^2))*sqrt(p*(1-p)+z^2/(4*n))
}
# AC.CI
AC.CI <- function(x, n, conf.level) {
z <- qnorm(1-(1-conf.level)/2)
x.s <- x + z^2/2
n.s <- n + z^2
p.s <- x.s/n.s
q.s <- 1-p.s
p.s + c(-1, 1)*z*sqrt(p.s*q.s/n.s)
}
# (b)
n <- 40
p <- 0.2
x.sim <- rbinom(10000, size=n, prob=p)
Wald.sim <- matrix(Wald.CI(x.sim, n=n, conf.level=0.95), nrow=2)
mean(Wald.sim[1,] < p & Wald.sim[2,] > p)
Wilson.sim <- matrix(Wilson.CI(x.sim, n=n, conf.level=0.95), nrow=2)
mean(Wilson.sim[1,] < p & Wilson.sim[2,] > p)
AC.sim <- matrix(AC.CI(x.sim, n=n, conf.level=0.95), nrow=2)
mean(AC.sim[1,] < p & AC.sim[2,] > p)
# problem 1
library(multtest)
data(golub)
gol.fac <- factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
# (a)
t.test(golub[2972, gol.fac=="ALL"], mu=-0.9, alternative = "greater")
# (b)
t.test(golub[2972, gol.fac=="ALL"],golub[2972, gol.fac=="AML"])
# (c)
t.test(golub[2972, gol.fac=="ALL"]-golub[2989, gol.fac=="ALL"], alternative = "less")
t.test(golub[2972, gol.fac=="ALL"], golub[2989, gol.fac=="ALL"], alternative = "less", paired=T )
# (d)
res <- golub[2972, gol.fac=="ALL"] < golub[2989, gol.fac=="ALL"]
binom.test(sum(res), length(res), p=1/2, alternative = "greater")
# (e)
res <- golub[2972,gol.fac=="ALL"] > -0.6
binom.test(sum(res), length(res), p=0.5, alternative = "less")
# (f)
resALL <- golub[2972, gol.fac=="ALL"] < -0.6
obsALL <- sum(resALL); nALL <- length(resALL)
resAML <- golub[2972, gol.fac=="AML"] < -0.6
obsAML <- sum(resAML); nAML <- length(resAML)
prop.test( x=c(obsALL, obsAML), n=c( nALL, nAML ), alternative="two.sided")
# problem 2
rm(list=ls())
# (a)
2000*0.05
# (b)
pbinom(89, size=2000, prob=0.05)
# problem 3
rm(list=ls())
#(a)
x.sim <- matrix(rnorm(10000*20, mean=3, sd=4), ncol=20)
tstat <- function(x) (mean(x)-3)/sd(x)*sqrt(length(x))
tstat.sim <- apply(x.sim, 1, tstat)
power.sim <- mean(tstat.sim > qt(0.3, df=19) & tstat.sim < qt(0.4, df=19))
power.sim+c(-1,0,1)*qnorm(0.975)*sqrt(power.sim*(1-power.sim)/10000)
x.sim <- matrix(rnorm(10000*20, mean=3, sd=4), ncol=20)
tstat <- function(x) (mean(x)-3)/sd(x)*sqrt(length(x))
tstat.sim <- apply(x.sim, 1, tstat)
power.sim <- mean(tstat.sim > qt(0.9, df=19) )
power.sim+c(-1,0,1)*qnorm(0.975)*sqrt(power.sim*(1-power.sim)/10000)
# problem 4
rm(list=ls())
# (a)
data(golub, package = "multtest")
gol.fac <- factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
p.values <- apply(golub, 1, function(x)
{
xALL = t(as.matrix(x))[,gol.fac=="ALL"]
xAML = t(as.matrix(x))[,gol.fac=="AML"]
t.test(xALL, xAML)$p.value
}
)
p.bon <-p.adjust(p=p.values, method="bonferroni")
p.fdr <-p.adjust(p=p.values, method="fdr")
sum(p.values<0.05)
sum(p.bon<0.05)
sum(p.fdr<0.05)
# (b)
golub.gnames[,2][order(p.values)][1:3]
golub.gnames[,2][order(p.bon)][1:3]
golub.gnames[,2][order(p.fdr)][1:3]
# problem 5
rm(list=ls())
# (a)
# Wald.CI
Wald.CI <- function(x, n, conf.level) {
p <- x/n
z <- qnorm(1-(1-conf.level)/2)
p + c(-1,1)*z*sqrt(p*(1-p)/n)
}
# Wilson.CI
Wilson.CI <- function(x, n, conf.level) {
p <- x/n
z <- qnorm(1-(1-conf.level)/2)
(x+z^2/2)/(n+z^2) + c(-1, 1)*(z*sqrt(n)/(n+z^2))*sqrt(p*(1-p)+z^2/(4*n))
}
# AC.CI
AC.CI <- function(x, n, conf.level) {
z <- qnorm(1-(1-conf.level)/2)
x.s <- x + z^2/2
n.s <- n + z^2
p.s <- x.s/n.s
q.s <- 1-p.s
p.s + c(-1, 1)*z*sqrt(p.s*q.s/n.s)
}
# (b)
n <- 40
p <- 0.2
x.sim <- rbinom(10000, size=n, prob=p)
Wald.sim <- matrix(Wald.CI(x.sim, n=n, conf.level=0.95), nrow=2)
mean(Wald.sim[1,] < p & Wald.sim[2,] > p)
Wilson.sim <- matrix(Wilson.CI(x.sim, n=n, conf.level=0.95), nrow=2)
mean(Wilson.sim[1,] < p & Wilson.sim[2,] > p)
AC.sim <- matrix(AC.CI(x.sim, n=n, conf.level=0.95), nrow=2)
mean(AC.sim[1,] < p & AC.sim[2,] > p)
x.sim <- matrix(rnorm(10000*20, mean=3, sd=4), ncol=20)
tstat <- function(x) (mean(x)-3)/sd(x)*sqrt(length(x))
tstat.sim <- apply(x.sim, 1, tstat)
power.sim <- mean(tstat.sim > qt(0.3, df=19) & tstat.sim < qt(0.4, df=19))
power.sim+c(-1,0,1)*qnorm(0.975)*sqrt(power.sim*(1-power.sim)/10000)
# original one
x.sim <- matrix(rnorm(10000*20, mean=3, sd=4), ncol=20)
tstat <- function(x) (mean(x)-3)/sd(x)*sqrt(length(x))
tstat.sim <- apply(x.sim, 1, tstat)
power.sim <- mean(tstat.sim > qt(0.9, df=19) )
power.sim+c(-1,0,1)*qnorm(0.975)*sqrt(power.sim*(1-power.sim)/10000)
