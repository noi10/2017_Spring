---
title: "MATH7340 HW13"
author: "Chengbo Gu"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Problem 1 (70 points) Analysis of the ALL data set.
##### (a) Define an indicator variable IsB such that IsB=TRUE for B-cell patients and IsB=FALSE for T-cell patients.
```{r}
library(ALL)
data(ALL)
IsB <- factor(ALL$BT %in% c("B", "B1", "B2", "B3", "B4"))
```

##### (b) Use two genes "39317_at" and "38018_g_at" to fit a classification tree for IsB. Print out the confusion matrix. Plot ROC curve for the tree.
```{r}
probedat <- as.matrix(exprs(ALL[c("39317_at", "38018_g_at"),]))
require(rpart)
c.tr <- rpart(IsB ~ ., data = data.frame(t(probedat)))
#plot(c.tr, branch=0,margin=0.1)
#text(c.tr, digits=3)
rpartpred <- predict(c.tr, type="class")
table(rpartpred, IsB)
```
```{r}
library(ROCR)
pred.prob <- predict(c.tr, type="prob")[,2]
pred <- prediction(pred.prob, IsB == "TRUE")
perf <- performance(pred, "tpr", "fpr")
plot(perf)
```

##### (c) Find its empirical misclassification rate (mcr), false negative rate (fnr) and specificity. Find the area under curve (AUC) for the ROC curve.
```{r}
# mcr
mcr <- sum(rpartpred != IsB)/length(IsB)
mcr

# fnr
fnr <- sum(rpartpred == "FALSE" & IsB == "TRUE")/sum(IsB == "TRUE")
fnr

# specificity
spec <- 1-fnr
spec

performance(pred, "auc")@y.values[[1]]
```



##### (d) Use 10-fold cross-validation to estimate its real false negative rate (fnr). What is your estimated fnr?
```{r}
require(caret)
data <- data.frame(IsB, t(probedat))
n <- dim(probedat)[2]
index <- 1:n
K <- 10
flds <- createFolds(index, k=K)
fnr.cv.raw <- rep(NA, K)
for (i in 1:K){
  testID <- flds[[i]]
  data.tr <- data[-testID,]
  data.test <- data[testID,]
  tree.cv <- rpart(IsB ~ ., data = data.tr)
  tree.cv.pred <- predict(tree.cv, newdata = data.test, type = "c")
  fnr.cv.raw[i] <- sum(tree.cv.pred == "FALSE" & data.test$IsB == "TRUE")/sum(data.test$IsB == "TRUE")
}
fnr.cv <- mean(fnr.cv.raw)
fnr.cv
```

##### (e) Do a logistic regression, using genes "39317_at" and "38018_g_at" to predict IsB. Find an 80% confidence interval for the coefficient of gene "39317_at".
```{r}
fit.lgr <- glm(IsB~. , family=binomial(link='logit'), data = data)
summary(fit.lgr)

confint(fit.lgr, level=0.8)
```

##### (f) Use n-fold cross-validation to estimate misclassification rate (mcr) of the logistic regression classifier. What is your estimated mcr?
```{r}
```

##### (g) Conduct a PCA on the scaled variables of the whole ALL data set (NOT just the two genes used above). We do this to reduce the dimension in term of genes (so this PCA should be done on the transpose of the matrix of expression values). To simply our future analysis, we use only the first K principal components (PC) to represent the data. How many PCs should be used? Explain how you arrived at your conclusion. Provide graphs or other R outputs to support your choice.
```{r, fig.width=12}
PCA<-prcomp(t(exprs(ALL)), scale=TRUE)
#summary(PCA)
importance <- summary(PCA)$importance[2,]
K = (1:128)
plot(K, importance, type='o', xaxt='n')
axis(1, at = K, las=2, cex.axis=0.65)
abline(v=8, col="red")
abline(v=12, col="red")
```

##### (h) Do a SVM classifier of IsB using only the first five PCs. (The number K=5 is fixed so that we all use the same classifier. You do not need to choose this number in the previous part (g).) What is the sensitivity of this classifier?
```{r}
library(e1071)
data.pca <- PCA$x[,1:5]
svm <- svm(data.pca, IsB, type = "C-classification", kernel = "linear")
svm.pred <- predict(svm , data.pca)

# tpr
sum(svm.pred == "TRUE" & IsB == "TRUE")/sum(IsB == "TRUE")
```

##### (i) Use leave-one-out cross-validation to estimate misclassification rate (mcr) of the SVM classifier. Report your estimate.
```{r}
n <- dim(data.pca)[1]
svm.mcr.cv.raw <- rep(NA, n)

for (i in 1:n){
  svm.cv <- svm(data.pca[-i,], IsB[-i], type = "C-classification", kernel="linear")
  svm.cv.pred <- predict(svm.cv, t(data.pca[i,]))
  svm.mcr.cv.raw[i]<-svm.cv.pred!=IsB[i]
}
svm.mcr.cv <- mean(svm.mcr.cv.raw)
svm.mcr.cv
```

##### (j) If you had to choose between classifiers in part (e) and in part (h), which one would you choose? Why?
```{r}
```